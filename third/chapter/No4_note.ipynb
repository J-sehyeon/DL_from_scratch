{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0d5d1c",
   "metadata": {},
   "source": [
    "# 제 4고지 : 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f3da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from dezero import Variable, Parameter\n",
    "from dezero import optimizers\n",
    "from dezero.utils import *\n",
    "from tools import plot_2dfunc\n",
    "from dezero.models import MLP\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb466d9",
   "metadata": {},
   "source": [
    "## step38 : 형상 변환 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d94e1",
   "metadata": {},
   "source": [
    "transpose 함수는 단순히 2차원 행렬을 전치시키는 것 뿐만 아니라 형상의 인덱스 위치를 변경할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460046e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 2)\n",
      "variable([[[-0.31664991  0.05976221]\n",
      "           [-1.16458472 -0.66508818]\n",
      "           [ 1.38220631 -1.00647365]\n",
      "           [-0.21247919  0.2440804 ]]\n",
      "         \n",
      "          [[-0.84664     0.20073327]\n",
      "           [-0.58339933  0.31138723]\n",
      "           [ 1.35237131  1.02193472]\n",
      "           [ 0.12215831 -0.77173851]]\n",
      "         \n",
      "          [[-1.11174058  0.82383281]\n",
      "           [ 1.42443297 -1.05153423]\n",
      "           [-1.4322244  -0.95115303]\n",
      "           [-1.210362   -0.45039212]]])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(np.random.randn(2, 3, 4))\n",
    "\n",
    "y = x.transpose(1, 2, 0)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6565d",
   "metadata": {},
   "source": [
    "원소의 개수는 형상의 숫자를 모두 곱한 값과 같다. 원소의 개수를 유지하는 상태에서 형상을 변화시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb5d91b",
   "metadata": {},
   "source": [
    "## step40 : 브로드캐스트 함수\n",
    "> 브로드캐스트란 형상이 다른 다차원 배열끼리의 연산을 가능하게 하는 넘파이 기능이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a913e3b",
   "metadata": {},
   "source": [
    "dezero 프레임워크는 넘파이 기반임을 알고는 있었지만 생각보다 많이 의존한다는 생각이 들었다. <br>그러니까 프레임워크의 설계에 중점을 두고 그 외 브로드캐스트의 정확한 구현같은 것들은 넘파이의 기능으로 대체하여 간편하게 설명한다.\n",
    "이번 단계에서는 브로드캐스팅 기능을 Function 클래스에 속하게 하여서 순전파와 역전파에서 사용 가능하도록 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5f1ef",
   "metadata": {},
   "source": [
    "함수에서 브로드캐스팅이 일어난다면 **\"브로드캐스팅 -> 함수 계산\"** 순서일 것이다. 따라서 역전파의 구현 순서는 기존 함수 구조에서 역전파 계산 이후<br>\n",
    "순선파시의 브로드캐스팅 여부 확인 후 형상 조정, 즉 **\"기울기 계산 -> sum_to\"** 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d694ff",
   "metadata": {},
   "source": [
    "## step42 : 선형 회귀\n",
    "> 회귀란 x값에 대한 실수값 y를 찾는 과정, 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c260388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([[0.64433458]]) variable([1.29473389]) variable(42.296340129442335)\n",
      "variable([[2.28830557]]) variable([5.37981674]) variable(0.08694585483964615)\n",
      "variable([[2.11563939]]) variable([5.46732269]) variable(0.07901006311507543)\n"
     ]
    }
   ],
   "source": [
    "# 토이 데이터셋\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 5 + 2 * x + np.random.rand(100, 1)\n",
    "x, y = Variable(x), Variable(y)         # 생략 가능\n",
    "\n",
    "W = Variable(np.zeros((1, 1)))\n",
    "b = Variable(np.zeros(1))\n",
    "\n",
    "def predict(x):\n",
    "    y = F.matmul(x, W) + b\n",
    "    return y\n",
    "\n",
    "def mean_squared_error(x0, x1):\n",
    "    diff = x0 - x1\n",
    "    return F.sum(diff ** 2) / len(diff)\n",
    "\n",
    "lr = 0.1\n",
    "iters = 101\n",
    "\n",
    "for i in range(iters):\n",
    "    y_pred = predict(x)\n",
    "    loss = mean_squared_error(y, y_pred)\n",
    "\n",
    "    W.cleargrad()\n",
    "    b.cleargrad()\n",
    "    loss.backward()\n",
    "\n",
    "    W.data -= lr * W.grad.data      # data 속성은 반드시 ndarray 인스턴스이어야 한다. 따라서 데이터 갱신 때 계산 그래프가\n",
    "    b.data -= lr * b.grad.data      # 업데이트되지 않는다.\n",
    "    if i % 50 == 0:\n",
    "        print(W, b, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f924060",
   "metadata": {},
   "source": [
    "위의 mse함수는 메모리에 diff와 그것의 제곱,그리고 합한 값까지 총 세개의 추가적인 메모리를 낭비하게 된다.<br>\n",
    "그치만, 이를 class화 시켜서 함수로 만든다면 계산그래프는 3개의 노드에서 1개의 노드로 줄 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad12504",
   "metadata": {},
   "source": [
    "### 오류 해결\n",
    "> Linear 함수의 순전파를 dezero 함수로 구성할 경우 ndarray로 들어온 data들을 전부 Variable객체로 변환하게 된다.<br>\n",
    "이렇게 되면 Variable객체의 data 또한 Variable객체가 되어서 이후 연산 수행 시 새로 생기는 변수가 Variable객체인 상태로 Variable클래스의 초기화 함수에 들어가 오류를 일으킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ffb72",
   "metadata": {},
   "source": [
    "## step43 : 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a112843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.8473695850105871)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)\n",
    "\n",
    "# 가중치 초기화\n",
    "I, H, O = 1, 10, 1\n",
    "W1 = Variable(0.01 * np.random.randn(I, H))\n",
    "b1 = Variable(np.zeros(H))\n",
    "W2 = Variable(0.01 * np.random.randn(H, O))\n",
    "b2 = Variable(np.zeros(O))\n",
    "\n",
    "# 신경망 추론\n",
    "def predict(x):\n",
    "    y = F.linear(x, W1, b1)\n",
    "    y = F.sigmoid(y)\n",
    "    y = F.linear(y, W2, b2)\n",
    "    return y\n",
    "\n",
    "lr = 0.2\n",
    "iters = 1000\n",
    "\n",
    "# 신경망 학습\n",
    "for i in range(iters):\n",
    "    y_pred = predict(x)\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "\n",
    "    W1.cleargrad()\n",
    "    b1.cleargrad()\n",
    "    W2.cleargrad()\n",
    "    b2.cleargrad()\n",
    "    loss.backward()\n",
    "\n",
    "    W1.data -= lr * W1.grad.data\n",
    "    b1.data -= lr * b1.grad.data\n",
    "    W2.data -= lr * W2.grad.data\n",
    "    b2.data -= lr * b2.grad.data\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef70414",
   "metadata": {},
   "source": [
    "위 모양과 라이브러리를 사용할 때의 모양이 점점 닮아진다.<br>\n",
    "그리고 I, H, O는 각각 입력, 은닉, 출력 층의 차원 수를 의미한다.<br>\n",
    "매개변수 초기화는 0이 아닌 임의의 값을 사용하는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ccd6bf",
   "metadata": {},
   "source": [
    "## step44 : 매개변수를 모아두는 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79297646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p1', 'p2'}\n",
      "------------------------------------------------------------\n",
      "p1 variable(1)\n",
      "p2 variable(2)\n"
     ]
    }
   ],
   "source": [
    "layer = L.Layer()\n",
    "\n",
    "layer.p1 = Parameter(np.array(1))\n",
    "layer.p2 = Parameter(np.array(2))\n",
    "layer.p3 = Variable(np.array(3))\n",
    "layer.p4 = 'test'\n",
    "\n",
    "print(layer._params)\n",
    "print('-'*60)\n",
    "\n",
    "for name in layer._params:\n",
    "    print(name, layer.__dict__[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c946401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.8165178479901415)\n",
      "variable(0.2499028014603371)\n",
      "variable(0.24609874026436834)\n",
      "variable(0.23721586110833612)\n",
      "variable(0.20793217994822144)\n",
      "variable(0.12311919860580511)\n",
      "variable(0.0788816839034867)\n",
      "variable(0.0765607529785731)\n",
      "variable(0.0764336464779914)\n",
      "variable(0.07619374494842987)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)\n",
    "\n",
    "l1 = L.Linear(10)   # 출력 크기 지정\n",
    "l2 = L.Linear(1)\n",
    "\n",
    "def predict(x):\n",
    "    y = l1(x)\n",
    "    y = F.sigmoid(y)\n",
    "    y = l2(y)\n",
    "    return y\n",
    "\n",
    "lr =  0.2\n",
    "iters = 10000\n",
    "\n",
    "for i in range(iters):\n",
    "    y_pred = predict(x)\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "\n",
    "    l1.cleargrads()\n",
    "    l2.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    for l in [l1, l2]:\n",
    "        for p in l.params():\n",
    "            p.data -= lr * p.grad.data\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222e968",
   "metadata": {},
   "source": [
    "## step45 : 계층을 모아두는 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9c7dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([0. 0. 0.])\n",
      "variable(None)\n",
      "variable([0. 0. 0. 0. 0.])\n",
      "variable(None)\n"
     ]
    }
   ],
   "source": [
    "model = L.Layer()\n",
    "model.l1 = L.Linear(5)\n",
    "model.l2 = L.Linear(3)\n",
    "\n",
    "def predict(model, x):\n",
    "    y = model.l1(x)\n",
    "    y = F.sigmoid(y)\n",
    "    y = model.l2(y)\n",
    "    return y\n",
    "\n",
    "for p in model.params():        # 순전파 실행을 하지 않아서 가중치는 None이다.\n",
    "    print(p)\n",
    "\n",
    "model.cleargrads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920aa7d",
   "metadata": {},
   "source": [
    "## step47 : 소프트맥스 함수와 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8be92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(1.1784240974937457)\n"
     ]
    }
   ],
   "source": [
    "model = MLP((10, 3))\n",
    "x = np.array([[0.2, -0.4], [0.3, 0.5], [1.3, -3.2], [2.1, 0.3]])\n",
    "t = np.array([2, 0, 1, 0])\n",
    "y = model(x)\n",
    "loss = F.softmax_cross_entropy_simple(y, t)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cbb0b",
   "metadata": {},
   "source": [
    "## step48 : 다중 클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd11a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.13\n",
      "epoch 31, loss 0.71\n",
      "epoch 61, loss 0.64\n",
      "epoch 91, loss 0.46\n",
      "epoch 121, loss 0.36\n",
      "epoch 151, loss 0.25\n",
      "epoch 181, loss 0.20\n",
      "epoch 211, loss 0.17\n",
      "epoch 241, loss 0.15\n",
      "epoch 271, loss 0.14\n",
      "epoch 300, loss 0.13\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "lr = 1.0\n",
    "\n",
    "x, t = dezero.datasets.Spiral(train=True)\n",
    "model = MLP((hidden_size, 3))\n",
    "optimizer = optimizers.SGD(lr).setup(model)\n",
    "\n",
    "data_size = len(x)\n",
    "max_iter = math.ceil(data_size / batch_size)    # 소수점 반올림\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    index = np.random.permutation(data_size)\n",
    "    sum_loss = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        batch_index = index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch_x = x[batch_index]\n",
    "        batch_t = t[batch_index]\n",
    "\n",
    "        y = model(batch_x)\n",
    "        loss = F.softmax_cross_entropy_simple(y, batch_t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(batch_t)\n",
    "    if epoch % 30 == 0:\n",
    "        avg_loss = sum_loss / data_size\n",
    "        print('epoch %d, loss %.2f' % (epoch + 1, avg_loss))\n",
    "avg_loss = sum_loss / data_size\n",
    "print('epoch %d, loss %.2f' % (epoch + 1, avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c13afc",
   "metadata": {},
   "source": [
    "## step49 : Dataset 클래스와 전처리\n",
    "> __getitem__ 과 __len__ 이 정의되어야 한다.<br>\n",
    "큰 용량의 데이터에 대해서는 미리 메모리상에 모든 데이터를 올리는게 아니라 배치 단위의 데이터만 불러온다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966431a",
   "metadata": {},
   "source": [
    "DataLoader는 __next__ 와 __iter__ 를 통해 미니배치 단위로 데이터셋을 나눠준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f51d0",
   "metadata": {},
   "source": [
    "## step50 : 미니배치를 뽑아주는 DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd211f",
   "metadata": {},
   "source": [
    "N개의 피쳐에 대한 1개의 정답 -> shape이 다를 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
